{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import collections\n",
    "import subprocess\n",
    "\n",
    "def prettify(atom):\n",
    "\n",
    "    s = atom['predicate']\n",
    "    if 'terms' in atom:\n",
    "        s += '('\n",
    "        ts = [prettify(t) for t in atom['terms']]\n",
    "        s += ','.join(ts)\n",
    "        s += ')'\n",
    "    return s\n",
    "\n",
    "  \n",
    "def parse_json_result(out):\n",
    "    \"\"\"Parse the provided JSON text and extract a dict\n",
    "    representing the predicates described in the first solver result.\"\"\"\n",
    "    result = json.loads(out)\n",
    "    assert len(result['Call']) > 0\n",
    "    if 'Witnesses' not in result['Call'][0]:\n",
    "        return []\n",
    "    \n",
    "    if len(result['Call'][0]['Witnesses']) == 0:\n",
    "        return []\n",
    "    \n",
    "    all_preds = []\n",
    "    ids = range(len(result['Call'][0]['Witnesses']))\n",
    "    \n",
    "    witness = result['Call'][0]['Witnesses'][0]['Value']\n",
    "\n",
    "    class identitydefaultdict(collections.defaultdict):\n",
    "        def __missing__(self, key):\n",
    "            return key\n",
    "\n",
    "    preds = collections.defaultdict(list)\n",
    "    env = identitydefaultdict()\n",
    "\n",
    "    for atom in witness:\n",
    "        parsed,dummy = parse_terms(atom)\n",
    "        preds[parsed[0]['predicate']].append(parsed)\n",
    "    return preds\n",
    "\n",
    "def solve(args):\n",
    "    \"\"\"Run clingo with the provided argument list and return the parsed JSON result.\"\"\"\n",
    "\n",
    "    args = ['clingo','--outf=2'] + args\n",
    "    clingo = subprocess.Popen(\n",
    "        ' '.join(args),\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        shell=True\n",
    "        )\n",
    "    out, err = clingo.communicate()\n",
    "            \n",
    "    return parse_json_result(out)\n",
    "\n",
    "def parse_terms(arguments):\n",
    "    terms = []\n",
    "    while len(arguments) > 0:\n",
    "        l_paren = arguments.find('(')\n",
    "        r_paren = arguments.find(')')\n",
    "        comma = arguments.find(',')\n",
    "        if l_paren < 0:\n",
    "            l_paren = len(arguments)-1\n",
    "        if r_paren < 0:\n",
    "            r_paren = len(arguments)-1\n",
    "        if comma < 0:\n",
    "            comma = len(arguments)-1\n",
    "        next = min(l_paren,r_paren,comma)\n",
    "        next_c = arguments[next]\n",
    "        if next_c == '(':\n",
    "        \n",
    "            pred = arguments[:next]\n",
    "            sub_terms, arguments = parse_terms(arguments[next+1:]) \n",
    "            terms.append({'predicate':pred,'terms':sub_terms})\n",
    "        elif next_c == ')':\n",
    "            pred = arguments[:next]\n",
    "            if pred != '':\n",
    "                terms.append({'predicate':arguments[:next]})\n",
    "            arguments = arguments[next+1:]\n",
    "            return terms,arguments\n",
    "        elif next_c == ',':\n",
    "            pred = arguments[:next]\n",
    "            if pred != '':\n",
    "                terms.append({'predicate':arguments[:next]})\n",
    "            arguments = arguments[next+1:]\n",
    "        else:\n",
    "            terms.append({'predicate':arguments})\n",
    "            arguments = ''\n",
    "    return terms, ''\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filenames = ['pong.lp','kaboom.lp']\n",
    "\n",
    "games = []\n",
    "types = {}\n",
    "facts = []\n",
    "for filename in filenames:\n",
    "    rules = open(filename,'rb').read().replace(' ','').replace('\\n','').split('.')[:-1]\n",
    "    rules = [parse_terms(rule)[0][0] for rule in rules]\n",
    "    per_game_facts = []\n",
    "    for rule in rules:\n",
    "        if rule['predicate'] == 'type':\n",
    "            types[rule['terms'][1]['predicate']] = rule['terms'][0]['predicate']\n",
    "        else: \n",
    "            facts.append(rule)\n",
    "            per_game_facts.append(rule)\n",
    "    games.append([prettify(rule) for rule in per_game_facts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def has_term(rule,term):\n",
    "    \n",
    "    if 'terms' in rule:\n",
    "        \n",
    "        for rule_term in rule['terms']:\n",
    "                if has_term(rule_term,term):\n",
    "                    return True\n",
    "        return False\n",
    "    elif rule['predicate'] == term:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def get_terms(rule):\n",
    "    if 'terms' in rule:\n",
    "        terms = []\n",
    "        for rule_term in rule['terms']:\n",
    "            terms += get_terms(rule_term)\n",
    "        return terms\n",
    "    else:\n",
    "        return [rule['predicate']]\n",
    "def get_higher_level(rule):\n",
    "    if 'terms' in rule:\n",
    "        \n",
    "        terms = [prettify(rule)]\n",
    "        for rule_term in rule['terms']:\n",
    "            terms += get_higher_level(rule_term)\n",
    "        return terms\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "    \n",
    "def get_predicates(rule):\n",
    "    if 'terms' in rule:\n",
    "        \n",
    "        terms = [rule]\n",
    "        for rule_term in rule['terms']:\n",
    "            terms += get_predicates(rule_term)\n",
    "        return terms\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "def get_term_positions(term,rule):\n",
    "    found = []\n",
    "    if 'terms' in rule:\n",
    "        for i,t in enumerate(rule['terms']):\n",
    "            if t['predicate'] == term:\n",
    "                found.append(i)\n",
    "    return found\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "\n",
    "max_rules = 2\n",
    "temperature = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import unionfind \n",
    "\n",
    "\n",
    "def replace(fact,source,target):\n",
    "    if 'terms' in fact:\n",
    "        terms = []\n",
    "        for fact_term in fact['terms']:\n",
    "            terms.append(replace(fact_term,source,target))\n",
    "        return {'predicate':fact['predicate'],\n",
    "                'terms':terms}\n",
    "    else:\n",
    "        pred = fact['predicate']\n",
    "        if pred == source:\n",
    "            pred = target\n",
    "        return {'predicate':pred}\n",
    "    \n",
    "def create_rule_graph(game,positives):\n",
    "    terms_to_fact = {}\n",
    "    \n",
    "    all_terms = {}\n",
    "    all_rules = {}\n",
    "    for positive_id,positive in enumerate(positives):\n",
    "        terms = get_terms(positive)\n",
    "        terms_to_fact = {term:[-positive_id-1]  for term in terms}\n",
    "        all_terms[-positive_id-1] = terms\n",
    "        all_rules[-positive_id-1] = positive\n",
    "        \n",
    "    \n",
    "    for rule_id,rule in enumerate(game):\n",
    "        terms = get_terms(rule)\n",
    "        all_terms[rule_id] = terms\n",
    "        for term in terms:\n",
    "            if term not in terms_to_fact:\n",
    "                terms_to_fact[term] = []\n",
    "            terms_to_fact[term].append(rule_id)\n",
    "        all_rules[rule_id] = rule\n",
    "        \n",
    "    children = {}\n",
    "    for term in terms_to_fact:        \n",
    "        for fact in terms_to_fact[term]:\n",
    "            rule = all_rules[fact]\n",
    "            all_predicates = get_predicates(rule)\n",
    "            for predicate in all_predicates:\n",
    "                positions = get_term_positions(term,predicate)\n",
    "                if predicate['predicate'] not in children:\n",
    "                    children[predicate['predicate']] = {}\n",
    "                for position in positions:\n",
    "                    if position not in children[predicate['predicate']]:\n",
    "                        children[predicate['predicate']][position] = set()\n",
    "                    children[predicate['predicate']][position].add(term)\n",
    "                \n",
    "    \n",
    "                \n",
    "    term2id = {t:i for i,t in enumerate(sorted(terms_to_fact))}\n",
    "    id2term = {i:t for t,i in term2id.items()}\n",
    "    union = unionfind.unionfind(len(terms_to_fact))\n",
    "    \n",
    "    for rule in children:\n",
    "        for pos in children[rule]:\n",
    "            children[rule][pos] = list(children[rule][pos])\n",
    "            for ii in range(len(children[rule][pos])):\n",
    "                for jj in range(ii+1,len(children[rule][pos])):\n",
    "                    union.unite(term2id[children[rule][pos][ii]],\n",
    "                                term2id[children[rule][pos][jj]])\n",
    "    \n",
    "    implicit_types = union.groups()\n",
    "    term2type = {}\n",
    "    for group in implicit_types:\n",
    "        group = [id2term[t] for t in group]\n",
    "        for t in group:\n",
    "            term2type[t] = group\n",
    "            \n",
    "            \n",
    "    for term in terms_to_fact:\n",
    "        for other in term2type[term]:\n",
    "            terms_to_fact[term] += terms_to_fact[other]\n",
    "        terms_to_fact[term] = list(set(terms_to_fact[term]))\n",
    "    visited = set()\n",
    "    connections = {}\n",
    "    \n",
    "    stack = list(sorted([i for i in all_terms if i < 0]))\n",
    "    #print stack\n",
    "    while len(stack) > 0:        \n",
    "        #print 'stack', stack\n",
    "        current = stack.pop(0)\n",
    "        visited.add(current)\n",
    "        if current not in connections:\n",
    "            connections[current] = set()\n",
    "        for term in all_terms[current]:\n",
    "            for connection in terms_to_fact[term]:\n",
    "                if connection not in visited and connection not in stack:\n",
    "                    if connection not in connections:\n",
    "                        connections[connection] = set()\n",
    "                    connections[connection].add(current)\n",
    "                    connections[current].add(connection)\n",
    "                        \n",
    "                    stack.append(connection)\n",
    "                elif connection != current:\n",
    "                    connections[connection].add(current)\n",
    "                    connections[current].add(connection)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return connections,all_rules\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_positives = []\n",
    "all_raw_positives = []\n",
    "\n",
    "test = 'player_affects_outcome'\n",
    "\n",
    "if test == 'player_controls':\n",
    "\n",
    "    positives = [{'predicate':'player_controls','terms':[{'predicate':'paddle_player'}]}]\n",
    "    all_raw_positives.append(positives[-1])\n",
    "    positives = [prettify(f) for f in positives]\n",
    "    all_positives.append(positives)\n",
    "\n",
    "\n",
    "    positives = [{'predicate':'player_controls','terms':[{'predicate':'basket'}]}]\n",
    "    all_raw_positives.append(positives[-1])\n",
    "    positives = [prettify(f) for f in positives]\n",
    "    all_positives.append(positives)\n",
    "elif test == 'moves':    \n",
    "    positives = [{'predicate':'moves','terms':[{'predicate':'paddle_player'}]},\n",
    "                {'predicate':'moves','terms':[{'predicate':'paddle_computer'}]}]\n",
    "    all_raw_positives += positives\n",
    "    positives = [prettify(f) for f in positives]\n",
    "    all_positives.append(positives)\n",
    "\n",
    "\n",
    "    positives = [{'predicate':'moves','terms':[{'predicate':'basket'}]},\n",
    "                 {'predicate':'moves','terms':[{'predicate':'bomb'}]},\n",
    "                {'predicate':'moves','terms':[{'predicate':'bomber'}]}]\n",
    "    all_raw_positives += positives\n",
    "    positives = [prettify(f) for f in positives]\n",
    "    all_positives.append(positives)\n",
    "elif test == 'player_affects_outcome':    \n",
    "    positives = [{'predicate':'player_affects_outcome','terms':[{'predicate':'player_serve'}]},\n",
    "                {'predicate':'player_affects_outcome','terms':[{'predicate':'move_up'}]},\n",
    "                {'predicate':'player_affects_outcome','terms':[{'predicate':'move_down'}]},\n",
    "                {'predicate':'player_affects_outcome','terms':[{'predicate':'player_hit'}]}]\n",
    "    all_raw_positives += positives\n",
    "    positives = [prettify(f) for f in positives]\n",
    "    all_positives.append(positives)\n",
    "\n",
    "\n",
    "    positives = [{'predicate':'player_affects_outcome','terms':[{'predicate':'defuse'}]},\n",
    "                 {'predicate':'player_affects_outcome','terms':[{'predicate':'move_right'}]},\n",
    "                {'predicate':'player_affects_outcome','terms':[{'predicate':'move_left'}]}]\n",
    "    all_raw_positives += positives\n",
    "    positives = [prettify(f) for f in positives]\n",
    "    all_positives.append(positives)\n",
    "\n",
    "connections,rules = create_rule_graph(facts,all_raw_positives)\n",
    "\n",
    "for c in sorted(connections):\n",
    "    print prettify(rules[c])\n",
    "    \n",
    "    for t in sorted([prettify(rules[cc]) for cc in connections[c]]):\n",
    "        print '\\t->',t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def coarsenings(head,body):\n",
    "    possible_coarsenings = []\n",
    "    all_high_level_terms = set()\n",
    "    term_usage = {}\n",
    "    terms = get_terms(head)\n",
    "    for term in terms:\n",
    "        if term not in term_usage:\n",
    "            term_usage[term] = []\n",
    "        term_usage[term].append(-1)\n",
    "\n",
    "\n",
    "    for pred_id,predicate in enumerate(body):\n",
    "        high_level_terms = get_higher_level(predicate)\n",
    "        all_high_level_terms |= set(high_level_terms)\n",
    "        terms = get_terms(predicate)\n",
    "        for term in terms:\n",
    "            if term not in term_usage:\n",
    "                term_usage[term] = []\n",
    "            term_usage[term].append(pred_id)\n",
    "    safe_terms = set(all_high_level_terms)\n",
    "\n",
    "    for high_level in all_high_level_terms:\n",
    "        for term in term_usage:\n",
    "            if len(term_usage[term]) > 1 and term in high_level:\n",
    "                safe_terms.remove(high_level)\n",
    "                break\n",
    "\n",
    "    return list(safe_terms)\n",
    "\n",
    "def coarsen(coarsenings_,body):\n",
    "    new_rules = []\n",
    "    coarsening2ind = {coarsening:'V{}'.format(i) for i,coarsening in enumerate(coarsenings_)}\n",
    "    ind2coarsening = {'V{}'.format(i):coarsening for i,coarsening in enumerate(coarsenings_)}\n",
    "\n",
    "    new_body = []\n",
    "    for b in body:\n",
    "\n",
    "        pretty_b = prettify(b)\n",
    "        for i in sorted(ind2coarsening):\n",
    "            c = ind2coarsening[i]\n",
    "            pretty_b = pretty_b.replace(c,i)\n",
    "\n",
    "        new_body.append(parse_terms(pretty_b)[0][0])\n",
    "    return new_body\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "def get_neighbors(points,connections,rules):\n",
    "    neighbors = set()\n",
    "    \n",
    "    for point in points:\n",
    "        for conn in connections[point]:\n",
    "            neighbors.add(tuple(sorted(set(points) | set([conn]))))\n",
    "    return neighbors\n",
    "\n",
    "def get_all_combinations(points,lhs,rules):\n",
    "    rules_to_use = [rules[point] for point in points]\n",
    "    uniques = set()\n",
    "        \n",
    "    for fact_id, fact in enumerate(rules_to_use):\n",
    "        terms = set(get_terms(fact))\n",
    "        uniques |= terms #set([(fact_id,term) for term in terms])\n",
    "    unique_combos = []\n",
    "    for ii in range(0,len(uniques)+1):\n",
    "        unique_combos += list(itertools.combinations(uniques,ii))\n",
    "    output = []\n",
    "    for uniques in unique_combos:   \n",
    "        uniques = sorted(uniques)\n",
    "        unique_mapping = {}\n",
    "        for unique_id,u in enumerate(uniques):\n",
    "            unique_mapping[u] = 'V{}'.format(unique_id) #random.randint(0,len(by_type[t])))\n",
    "        final_facts = [] \n",
    "        for fact_id, fact in enumerate(rules_to_use):            \n",
    "            terms = set(get_terms(fact))\n",
    "            for term in terms:\n",
    "                if term in unique_mapping:\n",
    "                    fact = replace(fact,term,unique_mapping[term])\n",
    "            final_facts.append(fact)\n",
    "        target_form = lhs\n",
    "        terms = list(set(get_terms(target_form)))\n",
    "        for term in terms:\n",
    "            if term in unique_mapping:\n",
    "                target_form = replace(target_form,term,unique_mapping[term])\n",
    "        potential_coarsenings = coarsenings(target_form,final_facts)\n",
    "        \n",
    "        coarsening_combos = []\n",
    "        for ii in range(0, len(potential_coarsenings)+1):\n",
    "            coarsening_combos += list(itertools.combinations(potential_coarsenings,ii))\n",
    "        \n",
    "        for coarsening in sorted(coarsening_combos):\n",
    "            coarsened = coarsen(coarsening,final_facts)\n",
    "            \n",
    "            \n",
    "        \n",
    "            by_term = {}\n",
    "            for fact_id, fact in enumerate(coarsened):\n",
    "                terms = set(get_terms(fact))\n",
    "                for term in terms:\n",
    "                    if term not in by_term:\n",
    "                        by_term[term] = set()\n",
    "                    by_term[term].add(fact_id)\n",
    "                    \n",
    "            able_to_be_negated = []\n",
    "            for fact_id, fact in enumerate(coarsened):\n",
    "                terms = set(get_terms(fact))\n",
    "                can_be_negated = True\n",
    "                for term in terms:\n",
    "                    if len(by_term[term]) == 1 and term[0].isupper():\n",
    "                        can_be_negated = False\n",
    "                        break\n",
    "                if can_be_negated:\n",
    "                    able_to_be_negated.append(fact_id)\n",
    "            \n",
    "            negation_combos = []\n",
    "            for ii in range(0,len(able_to_be_negated)+1):\n",
    "                negation_combos  += list(itertools.combinations(able_to_be_negated,ii))\n",
    "            \n",
    "            \n",
    "            for negation_combo in negation_combos:\n",
    "                negations = [False]*len(coarsened)\n",
    "                for n in negation_combo:\n",
    "                    negations[n] = True\n",
    "                output.append((target_form,coarsened,negations))\n",
    "    return output\n",
    "\n",
    "def score_rule(games,rule,per_game_positives):\n",
    "    head, body, negations = rule\n",
    "    probability = 0\n",
    "    for game,positives in zip(games,per_game_positives):\n",
    "            \n",
    "        rule_string = '.\\n'.join(game)\n",
    "        \n",
    "        \n",
    "        rule_string += '.\\n' + rule_to_string(rule)\n",
    "        hashed_name = 'temp' + hashlib.sha224(rule_string).hexdigest()\n",
    "        with open(hashed_name,'wb') as outfile:\n",
    "            outfile.write('.\\n'.join(game) + '.\\n')\n",
    "            outfile.write(rule_to_string(rule))\n",
    "            outfile.write('#show {}/{}.'.format(head['predicate'],len(head['terms'])))\n",
    "                \n",
    "        \n",
    "        solved = solve([hashed_name])\n",
    "        \n",
    "        is_good = True\n",
    "        found = []\n",
    "        total_found = 0\n",
    "        for t in solved:\n",
    "            for tt in solved[t]:\n",
    "                for ttt in tt:\n",
    "                    if prettify(ttt) in positives:\n",
    "                        found.append(prettify(ttt))\n",
    "                    else:\n",
    "                        is_good = False\n",
    "                        break\n",
    "                if not is_good:\n",
    "                    break\n",
    "            if not is_good:\n",
    "                break\n",
    "            if is_good:\n",
    "                total_found += 1\n",
    "        if is_good:\n",
    "            if total_found == 0:\n",
    "                probability += np.log(1e-20)\n",
    "            else:\n",
    "                probability += np.log(float(total_found)/float(len(positives)))\n",
    "        else:\n",
    "            probability += np.log(1e-20)\n",
    "        \n",
    "    return -probability\n",
    "def rule_to_string(rule):\n",
    "    head,body,negations = rule\n",
    "    \n",
    "    rule_text = []\n",
    "    for n,r in zip(negations,body):\n",
    "        if n:\n",
    "            rule_text.append('not '+prettify(r))\n",
    "        else:\n",
    "            rule_text.append(prettify(r))\n",
    "    return prettify(head) + ':-' + ','.join(list(sorted(rule_text))) + '.\\n'\n",
    "def breadth_first(connections,rules):    \n",
    "    starting_points = []\n",
    "    for connection in sorted(connections):\n",
    "        if connection < 0:\n",
    "            starting_points.append([connection])\n",
    "            \n",
    "    to_visit = [tuple(pt) for pt in starting_points]\n",
    "    max_size = 3\n",
    "    tested_rules = set()\n",
    "    visited = set()\n",
    "    visited |= set(to_visit)\n",
    "    while len(to_visit) > 0:\n",
    "        current = to_visit.pop(0)\n",
    "        print len(visited),  len(current), len(tested_rules)\n",
    "        if len(current) > max_size:\n",
    "            break\n",
    "            \n",
    "        lhses = [c for c in current if c < 0]\n",
    "        to_test = []\n",
    "        for lhs in lhses:\n",
    "            if len(current) > 1:\n",
    "                shrunk = set(current)\n",
    "                shrunk.remove(lhs)\n",
    "                to_test += get_all_combinations(shrunk,rules[lhs],rules)                \n",
    "            #to_test += get_all_combinations(current,rules[lhs],rules)\n",
    "        scored_rules = {}\n",
    "        \n",
    "        \n",
    "        for rule in to_test:\n",
    "            terms = get_terms(rule[0])\n",
    "            \n",
    "            for r in rule[1]:\n",
    "                terms += get_terms(r)\n",
    "            terms = set(terms)\n",
    "            specifics = 0\n",
    "            general = 0\n",
    "            for term in terms:\n",
    "                if term[0].islower():\n",
    "                    specifics +=1\n",
    "                else:\n",
    "                    general += 1\n",
    "            score = 1000*specifics+general\n",
    "            if score not in scored_rules:\n",
    "                scored_rules[score] = {}\n",
    "                \n",
    "            rule_string = rule_to_string(rule)\n",
    "            \n",
    "            if rule_string not in tested_rules:\n",
    "                scored_rules[score][rule_to_string(rule)] = rule\n",
    "                tested_rules.add(rule_string)\n",
    "                #print 'testing', rule_string\n",
    "        \n",
    "        \n",
    "        for score in sorted(scored_rules):\n",
    "            for rule in scored_rules[score].values():\n",
    "                log_prob = score_rule(games,rule,all_positives)\n",
    "                if log_prob < 46 :\n",
    "                    print score,log_prob\n",
    "                    print prettify(rule[0]) , ':-'\n",
    "                    for r in rule[1]:\n",
    "                        print '\\t', prettify(r)\n",
    "                    print ''\n",
    "                    if log_prob < 0.0001:\n",
    "                        return rule\n",
    "                \n",
    "            \n",
    "        neighbors = get_neighbors(current,connections,rules)\n",
    "        neighbors = [tuple(sorted(neighbor)) for neighbor in neighbors]\n",
    "        neighbors = [neighbor for neighbor in neighbors if neighbor not in visited]\n",
    "        visited |= set(neighbors)\n",
    "        to_visit += neighbors\n",
    "        import os\n",
    "        os.system('rm temp*')\n",
    "breadth_first(connections,rules)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
